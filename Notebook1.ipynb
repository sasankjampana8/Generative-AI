{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autogen\n",
      "  Downloading autogen-0.3.1-py3-none-any.whl (350 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.1/350.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from autogen) (24.1)\n",
      "Requirement already satisfied: python-dotenv in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from autogen) (1.0.1)\n",
      "Requirement already satisfied: tiktoken in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from autogen) (0.7.0)\n",
      "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from autogen) (2.8.2)\n",
      "Requirement already satisfied: numpy<2,>=1.17.0 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from autogen) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.3 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from autogen) (1.51.2)\n",
      "Collecting diskcache\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flaml\n",
      "  Downloading FLAML-2.3.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.3/313.3 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: docker in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from autogen) (7.1.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from openai>=1.3->autogen) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from openai>=1.3->autogen) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from openai>=1.3->autogen) (0.27.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from openai>=1.3->autogen) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from openai>=1.3->autogen) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from openai>=1.3->autogen) (1.3.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from openai>=1.3->autogen) (0.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from pydantic!=2.6.0,<3,>=1.10->autogen) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from pydantic!=2.6.0,<3,>=1.10->autogen) (2.20.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from docker->autogen) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from docker->autogen) (2.32.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from tiktoken->autogen) (2024.9.11)\n",
      "Requirement already satisfied: idna>=2.8 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen) (1.0.5)\n",
      "Requirement already satisfied: certifi in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen) (2024.7.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->autogen) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jampanasasank/Documents/GenAI/genaienv/lib/python3.10/site-packages (from requests>=2.26.0->docker->autogen) (3.3.2)\n",
      "Installing collected packages: termcolor, flaml, diskcache, autogen\n",
      "Successfully installed autogen-0.3.1 diskcache-5.6.3 flaml-2.3.1 termcolor-2.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "model = Ollama(model='llama3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG System - Q/A from pdf's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_instruction = \"Question: {question}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(system_instruction)\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangChain!\\n\\nLangChain (short for Language Chain) is a groundbreaking AI technology that enables humans and machines to have more natural, human-like conversations. It's an innovative approach to language processing that focuses on building long-range dependencies between words in a sentence or text.\\n\\nIn traditional NLP (Natural Language Processing), AI models typically process text sequentially, focusing on individual words or short phrases. LangChain takes a different route by analyzing the relationships between words across longer stretches of text. This allows it to better capture nuances, context, and even humor!\\n\\nLangChain has many potential applications:\\n\\n1. **Improved chatbots**: By understanding the flow of conversation, LangChain can help create more responsive and engaging chatbots.\\n2. **Enhanced language translation**: LangChain's ability to grasp long-range dependencies can improve machine translation by considering the broader context.\\n3. **Content generation**: LangChain can assist in generating high-quality content by analyzing patterns and relationships within text.\\n4. **Conversational AI**: It can be used to create more natural-sounding conversational interfaces, such as virtual assistants or customer support agents.\\n\\nThe technology is still evolving, but it has the potential to revolutionize the way humans interact with machines and each other!\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What is LangChain?\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
